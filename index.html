<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Jinghui Chen | Home</title>
  <meta name="description" content="Homepage of Jinghui Chen">
  <meta name="author" content="Jinghui Chen">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton/normalize.css>
  <link rel="stylesheet" href=/libs/external/skeleton/skeleton.css>
  <link rel="stylesheet" href=/libs/custom/my_css.css>

  <!-- JQuery
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>


  <!-- Skeleton tabs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton_tabs/skeleton-tabs.css>
  <script src=/libs/external/skeleton_tabs/skeleton-tabs.js></script>

  <!-- Timeline
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/timeline.css>

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="stylesheet" href=/libs/external/github-prettify-theme.css>-->
  <script src=/libs/custom/my_js.js></script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.jpeg>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.jpeg>

  <!-- Google Analytics -->
<!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164072186-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-164072186-1');
  </script>
  

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <div class="row">
        <div class="three columns">
          <a href="/"><img title="Photo" class="u-max-full-width" src='/assets/profile-pics/pic_new.jpg'></a>
        </div>
        <div class="nine columns main-description">
            <h1>Jinghui Chen</h1>
            <!-- <p>(he/him/his)</p> -->
            <p>Assistant Professor, Ph.D.</p>
            <p>Penn State University</p>
            <p>Email: jzc5917 [at] psu [dot] edu</p>
            <p>

              <span onclick="window.open('https://scholar.google.com/citations?user=mKia7Y4AAAAJ&hl=en')" style="cursor: pointer">
                <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://twitter.com/netfox001')" style="cursor: pointer">
                <i class="fa fa-twitter" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://www.linkedin.com/in/jinghui-chen-53a2a692')" style="cursor: pointer">
                <i class="fa fa-linkedin-square" aria-hidden="true"></i>
              </span>

              <span onclick="window.open('https://github.com/jinghuichen')" style="cursor: pointer">
                <i class="fa fa-github" aria-hidden="true"></i>
              </span>

              
              
            </p>
        </div>
      </div>
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href=/index.html#about>About</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#news>News</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#publications>Publications</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#research>Research</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#students>Students</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#teaching>Teaching</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#service>Service</a></li>
          <!-- <li class="navbar-item"><a class="navbar-link" href=/index.html#resume>Vita</a></li> -->
        </ul>
      </div>
    </nav>

    <script>
function unhide(divID) {
  console.log(divID)
  var item = document.getElementById(divID);
  console.log('hi')
  if (item){
    item.className=(item.className=='hidden')?'unhidden':'hidden';
  }
}
</script>

<!-- ========== ABOUT ========== -->

<div class="docs-section">
  <span class="anchor" id="about"></span>
  <h4>About</h4>

  <p>
  I am an Assistant Professor in the <a href="https://ist.psu.edu/" target="_blank">College of Information Sciences and Technology</a> at Penn State University</a>. I received my Ph.D. in the Department of Computer Science, University of California, Los Angeles (UCLA) working with <a href="http://web.cs.ucla.edu/~qgu/" target="_blank">Prof. Quanquan Gu </a> in 2021. I received my B.E. in the Department of Electrical Engineering and Information Science at the University of Science and Technology of China in 2015.
  </p>



  <p style="color:#a70c0c;"><b>Prospective Students</b>: I’m looking for highly motivated PhD/intern students to join my group. The official PhD application deadline for the Fall 2024 application cycle is Dec 15, 2023 (<a href="https://ist.psu.edu/prospective/graduate/application/phd" target="_blank">details</a>). 
  <b>If you’re interested in joining my lab, please fill and see instructions in the following <a href="https://forms.office.com/r/xqPF6xmySq" target="_blank"> form</a></b> (feel free to skip optional questions). 

         <!-- See more info <a href="https://www.1point3acres.com/bbs/thread-792187-1-1.html" target="_blank"> here</a>. -->
      <!-- I will go over your applications and contact you if you fit our lab. You don’t have to send me another email, as the form will generate one automatically.  -->
      <!-- (Note that although we may not be able to respond to each individual message due to the large number of messages we receive, we do review all applications.) -->
  </p>


  <p> <strong style="color:#a70c0c;">Research Interests:</strong> 
  My research interests broadly include the theory and applications in different aspects of machine learning, with particular interests on building <strong style="color:#a70c0c;">efficient</strong> and <strong style="color:#a70c0c;">trustworthy</strong> machine learning models. Recently, we are particularly interested in the following research topics:
  <ul style="margin-left: 40px">
    <li>Trustworthiness and safety issues in Large Language Models (LLM alignments, LLM robustness, etc.)</li>
    <li>Security and privacy issues for other emerging machine learning models (multimodal foundation models, federated learning, diffusion models, etc.)</li>
    <li>Efficient optimization strategies for training large scale foundataion models/federated learning (adaptive gradient optimizers, parameter-efficient training, etc.)</li>

  </ul> 
 
  </p>  


</div>
 

<!-- ========== NEWS ========== -->
<!-- Had to add empty anchor to solve the problem of fixed header
     hiding part of paper
-->
<span class="anchor" id="news"></span>
<div class="docs-section">
  <h4>News</h4>
  <!-- <p> Scroll for older news </p> -->
  <UL style="list-style-type: none; padding: 2px; overflow-y: scroll; height:500px;">
    <li>
      [05/2025] Two papers are accepted to ICML 2025!  
    </li> 
    <li>
      [01/2025] One paper is accepted to NAACL 2025!  
    </li> 
    <li>
      [01/2025] One paper is accepted to USENIX 2025!  
    </li> 
    <li>
      [09/2024] Three papers are accepted to NeurIPS 2024!  
    </li> 
    <li>
      [09/2024] One paper is accepted to EMNLP 2024!  
    </li> 
    <li>
      [05/2024] Two papers are accepted to ACL 2024!  
    </li> 
    <li>
      [05/2024] Two papers are accepted to ICML 2024!  
    </li> 
    <li>
      [03/2024] Two papers are accepted to NAACL 2024!  
    </li> 
    <li>
      [01/2024] Two papers are accepted to ICLR 2024!  
    </li> 
    <li>
      [12/2023] One paper is accepted to AAAI 2024!  
    </li> 
    <li>
      [12/2023] Two papers are accepted to USENIX 2024!  
    </li> 
    <li>
      [09/2023] Five papers are accepted to NeurIPS 2023!  
    </li> 
    <li>
      [08/2023] We are organizing the <a href="https://federated-learning.org/fl@fm-neurips-2023/" target="_blank">Workshop on Federated Learning in the Age of Foundation Models</a> at NeurIPS 2023 (FL@FM-NeurIPS’23). Submissions are welcome! 
    </li> 
    <li>
      [08/2023] Our paper is accepted to CIKM 2023: "RoCourseNet: Robust Training of a Prediction Aware Recourse Model" 
    </li> 
    <li>
      [05/2023] Our paper is accepted to KDD 2023: "PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text" 
    </li> 
    <li>
      [05/2023] Our paper is accepted to UAI 2023: "Benign Overfitting in Adversarially Robust Linear Classification" 
    </li> 
    <li>
      [04/2023] Our paper is accepted to ICML 2023: "Graph Contrastive Backdoor Attacks" 
    </li> 
    <li>
      [01/2023] Our paper is accepted to WWW 2023: "Do Language Models Plagiarize?" 
    </li> 
    <li>
      [01/2023] Our paper is accepted to ICLR 2023: "Spectral Augmentation for Self-Supervised Learning on Graphs" 
    </li> 
    <li>
      [12/2022] Our paper is accepted to AAAI 2023: "On the Vulnerability of Backdoor Defenses for Federated Learning" 
    </li> 
    <li>
      [09/2022] Our paper is accepted to NeurIPS 2022: "One-shot Neural Backdoor Erasing via Adversarial Weight Masking" 
    </li> 
    <li>
      [05/2022] Our paper is accepted to KDD 2022: "LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization" 
    </li> 
    <li>
      [05/2022] Our paper is accepted to ICML 2022: "Communication-Efficient Adaptive Federated Learning" 
    </li>  
    <li>
      [05/2022] Dr. Chen recieved received Cisco Faculty Research Award!
    </li>   
    <li>
      [01/2022] Our paper is accepted to ICLR 2022: "Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations" 
    </li>    
    <li>
      [01/2022] Our paper is accepted to AISTATS 2022: "Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization" 
    </li>        
    <li>
      [12/2021] Our paper is accepted to AAAI 2022: "Efficient Robust Training via Backward Smoothing" 
    </li>  
    <li>
      [09/2021] Our paper is accepted to NeurIPS 2021:
       "Do Wider Neural Networks Really Help Adversarial Robustness?"
    </li>  
    <li>
      [06/2021] I recieved UCLA Outstanding Graduate Student Research Award. 
    </li> 
    <li>
      [04/2021] I will join the College of Information Sciences and Technology (IST) at Penn State University (PSU) in Fall 2021 as a tenure-track assistant professor. 
    </li> 
    <li>
      [07/2020] Released  <a href="https://github.com/uclaml/RayS" target="_blank">Model Robustness (ADBD) Leaderboard </a>under RayS attack: 
       Benchmarking state-of-the-art robust trained models with ADBD metric
    </li> 
    <li>
      [05/2020] Our paper is accepted to KDD 2020: 
       "RayS: A Ray Searching Method for Hard-label Adversarial Attack"
    </li> 
    <li>
      [04/2020] Our paper is accepted to IJCAI 2020:
       "Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks"
    </li> 
    <li>
      [04/2020] We just launched a project using machine learning and AI to combat Covid-19!
       <a href="https://covid19.uclaml.org/" target="_blank"> Live data visualization and new cases / peak predictions </a>
    </li> 
    <li>
      [01/2020] Our paper is accepted to AISTATS 2020:
       "Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models"
    </li> 
    <li>
      [11/2019] Our paper is accepted to AAAI 2020:
       "A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks" 
    </li> 
    
     
    
  </UL>
</div>




 



<!-- ========== PUBLICATIONS ========== -->
<div class="docs-section" id="publications">
  <h4>Publications</h4>

  <p>Full publications on <a href="https://scholar.google.com/citations?user=mKia7Y4AAAAJ&hl=en" target="_blank">Google Scholar</a>.
  <br> <sup><b>E</b></sup> indicates authors with equal contribution. <u>underline</u> indicates students supervised. </p> 

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#all">All</div></li>
    <li><div class="button" data-ref="#at">At PSU</div></li>    
  </ul>


  <div class="tab-content">
 
 
    <ol class="tab-pane active" id="all">


      <li class="paper">
        <b>TruthFlow: Truthful LLM Generation via Representation Flow Correction</b> 
        <br>
        <p><u>Hanyu Wang</u>, <u>Bochuan Cao</u>, <u>Yuanpu Cao</u>, and <b>Jinghui Chen</b>, <i>in Proceedings of the 42nd International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vancouver, Canada, 2025. </i>
        <a href="https://arxiv.org/abs/2502.04556" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models</b> 
        <br>
        <p>Yaopei Zeng, <u>Yuanpu Cao</u>, <u>Bochuan Cao</u>, Yurui Chang, <b>Jinghui Chen</b>, and Lu Lin, <i>in Proceedings of the 42nd International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vancouver, Canada, 2025. </i>
        <a href="https://arxiv.org/abs/2410.21471" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection</b></br>
        <p>Lee, Jooyoung, Toshini Agrawal, Adaku Uchendu, Thai Le, <b>Jinghui Chen</b>, and Dongwon Lee, <i>in Proceedings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Albuquerque, New Mexico, 2025. </i>
        <a href="https://arxiv.org/abs/2406.16288" target="_blank">[Paper]</a> </p>    
      </li>


      <li class="paper">
        <b>WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response</b> 
        <br>
        <p><u>Tianrong Zhang</u>, <u>Bochuan Cao</u>, <u>Yuanpu Cao</u>, Lu Lin, Prasenjit Mitra and <b>Jinghui Chen</b>, <i> in Findings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL Findings</strong>),  Albuquerque, New Mexico, 2025.</i>
        <a href="https://arxiv.org/abs/2405.14023" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion Models</b> 
        <br>
        <p>Changjiang Li, Ren Pang, <u>Bochuan Cao</u>, <b>Jinghui Chen</b>, Fenglong Ma, Shouling Ji and Ting Wang, <i>in Proceedings of the 34th USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Seattle, WA, USA, 2025.</i>
        <a href="https://arxiv.org/abs/2406.09669" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization</b> 
        <br>
        <p><u>Yuanpu Cao</u>, <u>Tianrong Zhang</u>, <u>Bochuan Cao</u>, Ziyi Yin, Lu Lin, Fenglong Ma and <b>Jinghui Chen</b>,<i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2406.00045" target="_blank">[Paper]</a>
        </p>
      </li>
 
      <li class="paper">
        <b>DFBA: Data Free Backdoor Attacks</b> 
        <br>
        <p><u>Bochuan Cao</u>, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, <b>Jinghui Chen</b> Bo Li, and Dawn Song, <i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2412.06219" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>FedMeKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection</b> 
        <br>
        <p>Jiaqi Wang<sup><b>E</b></sup>, Xiaochen Wang<sup><b>E</b></sup>, Lingjuan Lyu, <b>Jinghui Chen</b> and Fenglong Ma, <i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2408.09227" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models</b> 
        <br>
        <p>Xiaochen Wang<sup><b>E</b></sup>, Jiaqi Wang<sup><b>E</b></sup>, Houping Xiao, <b>Jinghui Chen</b> and Fenglong Ma, <i> in Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (<strong style="color:red;">EMNLP</strong>), Miami, Florida, 2024.</i>
        <a href="https://arxiv.org/abs/2408.10276" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>On the Data Heterogeneity in Adaptive Federated Learning</b></br>
        <p><u>Yujia Wang</u>, <b>Jinghui Chen<sup><b>E</b></sup></b>, <i>in Transactions on Machine Learning Research (<strong style="color:red;">TMLR</strong>), 2024.</i>
        <a href="https://openreview.net/forum?id=hv7iXsiBZE" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM</b> 
        <br>
        <p><u>Bochuan Cao</u><sup><b>E</b></sup>, <u>Yuanpu Cao</u><sup><b>E</b></sup>,  Lu Lin, and <b>Jinghui Chen</b>, <i>in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (<strong style="color:red;">ACL</strong>), Bangkok, Thailand, 2024. </i>
        <a href="https://arxiv.org/abs/2309.14348" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>Jailbreak Open-Sourced Large Language Models via Enforced Decoding</b> 
        <br>
        <p>Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, <u>Bochuan Cao</u>, Lu Lin, Jinyuan Jia, <b>Jinghui Chen</b> and Dinghao Wu, <i>in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (<strong style="color:red;">ACL</strong>), Bangkok, Thailand, 2024. </i>
        <a href="https://arxiv.org/abs/2310.01581" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>FADAS: Towards Federated Adaptive Asynchronous Optimization</b></br>
        <p><u>Yujia Wang</u>, Shiqiang Wang, Songtao Lu and <b>Jinghui Chen</b>, <i>in Proceedings of the 41st International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vienna, Austria, 2024. </i>
        <a href="https://arxiv.org/abs/2407.18365" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>Graph Adversarial Diffusion Convolution</b></br>
        <p>Songtao Liu, <b>Jinghui Chen</b>, Tianfan Fu, Lu Lin, Marinka Zitnik and Dinghao Wu, <i>in Proceedings of the 41st International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vienna, Austria, 2024. </i>
        <a href="https://arxiv.org/abs/2406.02059" target="_blank">[Paper]</a>
        </p>
      </li>

      
      <li class="paper">
        <b>Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections</b> 
        <br>
        <p><u>Yuanpu Cao</u>, <u>Bochuan Cao</u> and <b>Jinghui Chen</b>, <i> in Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Mexico City, Mexico, 2024.</i>
        <a href="https://arxiv.org/abs/2312.00027" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning</b> 
        <br>
        <p><u>Tianrong Zhang</u>, Zhaohan Xi, Ting Wang, Prasenjit Mitra and <b>Jinghui Chen</b>, <i> in Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Mexico City, Mexico, 2024.</i>
        <a href="https://arxiv.org/abs/2406.04478" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization</b></br>
        <p>Dongruo Zhou<sup><b>E</b></sup>, <b>Jinghui Chen<sup><b>E</b></sup></b>, Yuan Cao<sup><b>E</b></sup>, Ziyan Yang, and Quanquan Gu, <i>in Transactions on Machine Learning Research (<strong style="color:red;">TMLR</strong>), 2024.</i>
        <a href="https://arxiv.org/abs/1808.05671" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration</b></br>
        <p><u>Yujia Wang</u>, <u>Yuanpu Cao</u>, <u>Jingcheng Wu</u>, <u>Ruoyu Chen</u> and <b>Jinghui Chen</b>, <i>in Proceedings of the 25th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Vienna, Austria, 2024.</i> 
        <a href="https://openreview.net/forum?id=4aywmeb97I" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>Backdoor Contrastive Learning via Bi-level Trigger Optimization</b></br>
        <p><u>Weiyu Sun</u>, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, <b>Jinghui Chen</b> and Lu Lin, <i>in Proceedings of the 25th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Vienna, Austria, 2024.</i> 
        <a href="https://openreview.net/forum?id=oxjeePpgSP" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models</b> 
        <br>
        <p>Ziyi Yin, Muchao Ye, <u>Tianrong Zhang</u>, Jiaqi Wang, Han Liu, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Vancouver, Canada, 2024. </i>
        <a href="https://arxiv.org/abs/2402.11083" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>On the Difficulty of Defending Contrastive Learning against Backdoor Attacks</b> 
        <br>
        <p>Changjiang Li, Ren Pang, <u>Bochuan Cao</u>, Zhaohan Xi, <b>Jinghui Chen</b>, Shouling Ji and Ting Wang, <i>in Proceedings of the 33rd USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Philadelphia, PA, USA, 2024.</i>
        <a href="https://arxiv.org/abs/2312.09057" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?</b> 
        <br>
        <p>Yuanxin Zhuang, Chuan Shi, Mengmei Zhang, <b>Jinghui Chen</b>, Lingjuan Lyu, Pan Zhou and Lichao Sun,  <i>in Proceedings of the 33rd USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Philadelphia, PA, USA, 2024.</i>
        <a href="https://www.usenix.org/conference/usenixsecurity24/presentation/zhuang" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>Federated Learning with Projected Trajectory Regularization</b> 
        <br>
        <p><u>Tiejin Chen</u><sup><b>E</b></sup>, <u>Yuanpu Cao</u><sup><b>E</b></sup>, <u>Yujia Wang</u><sup><b>E</b></sup>, Cho-Jui Hsieh, and <b>Jinghui Chen</b>, <i>arXiv:2312.14380, 2023. </i>
        <a href="https://arxiv.org/abs/2312.14380" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI</b> 
        <br>
        <p><u>Bochuan Cao</u>, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li and <b>Jinghui Chen</b>, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2310.19248" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models</b><br>
        <p>Ziyi Yin, Muchao Ye, <u>Tianrong Zhang</u>, Tianyu Du, Jinguo Zhu, Han Liu, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2310.04655" target="_blank">[Paper]</a> 
        </p>
      </li>
 
      <li class="paper">
        <b>A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning</b></br>
        <p>Hangfan Zhang, Jinyuan Jia, <b>Jinghui Chen</b>, Lu Lin and Dinghao Wu, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://openreview.net/forum?id=S6ajVZy6FA" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks</b></br>
        <p>Tianyu Du, Zhaohan Xi, Changjiang Li, Ren Pang, Shouling Ji, <b>Jinghui Chen</b>, Fenglong Ma and Ting Wang, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2309.13256" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>UniT: A Unified Look at Certified Robust Training against Text Adversarial Perturbation</b></br>
        <p>Muchao Ye, Ziyi Yin, <u>Tianrong Zhang</u>, Tianyu Du, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://openreview.net/forum?id=oGxE2Nvlda" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>RoCourseNet: Robust Training of a Prediction Aware Recourse Model</b></br>
        <p>Hangzhi Guo, Feiran Jia, <b>Jinghui Chen</b>, Anna Squicciarini and Amulya Yadav, <i>in Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (<strong style="color:red;">CIKM</strong>), Birmingham, UK, 2023. </i>
        <a href="https://arxiv.org/abs/2206.00700" target="_blank">[Paper]</a> 
        </p>
    <!--     <p style="color:blue;">A short version of this paper also appears on ICML 2022 Workshop on Adversarial Machine Learning Frontiers. </p>
           <li class="paper-buttons">
              <a class="button" href="https://arxiv.org/abs/2206.00700" target="_blank">Paper</a>
          </li> -->
      </li>


      <li class="paper">
        <b>PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text</b></br>
        <p>Muchao Ye, <b>Jinghui Chen</b>, Chenglin Miao, Han Liu, Ting Wang and Fenglong Ma, <i> in Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), San Diego, CA, USA, 2023.</i>
        <a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599461" target="_blank">[Paper]</a>
        </p>           
      </li>

      <li class="paper">
        <b>Benign Overfitting in Adversarially Robust Linear Classification</b></br>
        <p><b>Jinghui Chen<sup><b>E</b></sup></b>, Yuan Cao<sup><b>E</b></sup>, and Quanquan Gu, <i> in Proceedings of the 39th Conference on Uncertainty in Artificial Intelligence (<strong style="color:red;">UAI</strong>), Pittsburgh, PA, USA, 2023.</i> <a href="https://arxiv.org/abs/2112.15250" target="_blank">[Paper]</a> </p>
         <!-- <p style="color:blue;">A short version of this paper also appears on ICML 2021 Workshop on Overparameterization: Pitfalls and Opportunities.</p> -->
      </li>

      <li class="paper">
        <b>Graph Contrastive Backdoor Attacks</b></br>
        <p>Hangfan Zhang, <b>Jinghui Chen</b>, Lu Lin, Jinyuan Jia and Dinghao Wu, <i> in Proceedings of the 40th International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Hawaii, USA, 2023. </i> 
        <a href="https://proceedings.mlr.press/v202/zhang23e/zhang23e.pdf" target="_blank">[Paper]</a> </p>
      </li>



      <li class="paper">
        <b>Multiple Models for Outbreak Decision Support in the Face of Uncertainty</b></br>
        <p>Katriona Shea, ..., <b>Jinghui Chen</b>, ..., Michael C. Runge., <i>in Proceedings of the National Academy of Sciences (<strong style="color:red;">PNAS</strong>), 2023.</i>
        <a href="https://www.pnas.org/doi/10.1073/pnas.2207537120" target="_blank">[Paper]</a> </p>
        </li>


      <li class="paper">
        <b>Do Language Models Plagiarize?</b></br>
        <p>Lee, Jooyoung, Thai Le, <b>Jinghui Chen</b>, and Dongwon Lee, <i>in Proceedings of the ACM Web Conference (<strong style="color:red;">WWW</strong>), Austin, Texas, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2203.07618" target="_blank">[Paper]</a> </p>    
      </li>


      <li class="paper">
        <b>Spectral Augmentation for Self-Supervised Learning on Graphs</b></br>
        <p>Lu Lin, <b>Jinghui Chen</b>, Hongning Wang, <i> in Proceedings of the 11th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Kigali Rwanda, 2023. </i>
        <a href="https://arxiv.org/abs/2210.00643" target="_blank">[Paper]</a>
        <a href="https://github.com/Louise-LuLin/GCL-SPAN" target="_blank">[Code]</a>
        </p>
        <!-- <p style="color:blue;">A short version of this paper also appears on NeurIPS 2022 Workshop on New Frontiers in Graph Learning. </p> -->         
      </li>

<!--       <li class="paper">
        <b>Robustness for Free: Adversarially Robust Anomaly Detection Through Diffusion Model</b></br>
        <p><u>Yuanpu Cao</u>, Lu Lin, and <b>Jinghui Chen</b>, <i> Technical Report. </i>
        <a href="https://openreview.net/forum?id=imIlOpuEsi" target="_blank">[Paper]</a>
        </p>
      </li> -->


      <li class="paper">
        <b>On the Vulnerability of Backdoor Defenses for Federated Learning</b></br> 
        <p><u>Pei Fang</u> and <b>Jinghui Chen</b>, 
        <i>  in Proceedings of the 37th Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Washington DC, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2301.08170" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/Focused-Flip-Federated-Backdoor-Attack" target="_blank">[Code]</a>
        </p>
          <!-- <p style="color:blue;">A short version of this paper also appears on International Workshop on Federated Learning: Recent Advances and New Challenges in Conjunction with NeurIPS 2022. </p> -->
        </li>
 
      <li class="paper">
        <b>One-shot Neural Backdoor Erasing via Adversarial Weight Masking</b></br>
        <p><u>Shuwen Chai</u>  and <b>Jinghui Chen</b>, <i> in Proceedings of the 36th Advances in Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, LA, USA, 2022. </i>
        <a href="https://arxiv.org/abs/2207.04497" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/AWM" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Accelerating Adaptive Federated Optimization with Local Gossip Communications</b></br>
        <p><u>Yujia Wang</u>, <u>Pei Fang</u> and <b>Jinghui Chen</b>, <i> in International Workshop on Federated Learning: Recent Advances and New Challenges in Conjunction with NeurIPS 2022 (<strong style="color:red;">FL-NeurIPS</strong>), 2022. </i>
        <a href="https://openreview.net/forum?id=wwXb1qmcBuD" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>How Powerful is Implicit Denoising in Graph Neural Networks</b></br>
        <p>Songtao Liu, Zhitao Ying, Hanze Dong, Lu Lin, <b>Jinghui Chen</b> and Dinghao Wu, <i>NeurIPS 2022 Workshop on New Frontiers in Graph Learning (<strong style="color:red;">GLFrontiers-NeurIPS</strong>). </i>
        <a href="https://arxiv.org/abs/2209.14514" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>The United States COVID-19 Forecast Hub dataset</b></br>
        <p>Estee Y Cramer, ..., <b>Jinghui Chen</b>, ..., Nicholas G. Reich, <i><strong style="color:red;">Scientific Data</strong>, 9(1), pp.1-15., 2022. </i>
        <a href="https://www.nature.com/articles/s41597-022-01517-w#" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization</b></br>
        <p>Muchao Ye, <b>Jinghui Chen</b>, Chenglin Miao, Ting Wang and Fenglong Ma, <i> in Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), Washington DC, USA, 2022. </i>
        <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539357" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Communication-Efficient Adaptive Federated Learning</b></br>
        <p><u>Yujia Wang</u>, Lu Lin and <b>Jinghui Chen</b>, <i> in Proceedings of the 39th International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Baltimore, Maryland, USA, 2022. </i>
        <a href="https://arxiv.org/abs/2205.02719" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/FedCAMS" target="_blank">[Code]</a>
        </p> 
      </li> 
    
      <li class="paper">
        <b>Evaluation of individual and ensemble probabilistic forecasts of COVID-19 mortality in the US</b></br>
        <p>Estee Y Cramer, ..., <b>Jinghui Chen</b>, ..., Nicholas G. Reich, <i>in Proceedings of the National Academy of Sciences (<strong style="color:red;">PNAS</strong>), 2022.</i>
        <a href="https://www.pnas.org/doi/full/10.1073/pnas.2113561119" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations</b></br>
        <p><u>Weiqi Peng</u> and <b>Jinghui Chen</b>, <i>in Proceedings of the 10th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Virtual, 2022.</i>
        <a href="https://openreview.net/forum?id=6VpeS27viTq" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/Learnability-Lock" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization</b></br>
        <p><u>Yujia Wang</u>, Lu Lin and <b>Jinghui Chen</b>, <i>in Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (<strong style="color:red;">AISTATS</strong>), Virtual, 2022. </i>
        <a href="https://arxiv.org/abs/2111.00705" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/CD-Adam" target="_blank">[Code]</a>
        </p>
        <!-- <p style="color:blue;">A short version of this paper also appears on International Workshop on Trustable, Verifiable and Auditable Federated Learning in Conjunction with AAAI 2022 (FL-AAAI-22). </p> -->
      </li>

      <li class="paper">
        <b>Efficient Robust Training via Backward Smoothing</b></br>
        <p><b>Jinghui Chen</b>, Yu Cheng, Zhe Gan, Quanquan Gu and Jingjing Liu, <i>In Proceedings of the 36th AAAI Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Vancouver, BC, Canada, 2022.</i>
        <a href="https://arxiv.org/abs/2010.01278" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/BackwardSmoothing" target="_blank">[Code]</a>
        </p>
      </li>
   
      <li class="paper">
        <b>Do Wider Neural Networks Really Help Adversarial Robustness?</b></br>
        <p>Boxi Wu<sup><b>E</b></sup>, <b>Jinghui Chen<sup><b>E</b></sup></b>, Deng Cai, Xiaofei He and Quanquan Gu, <i>in Proceedings of the 35th Advances in Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Virtual, 2021.</i>
        <a href="https://arxiv.org/abs/2010.01279" target="_blank">[Paper]</a>
        </p>
      </li>

     <li class="paper">
        <b>Epidemic Model Guided Machine Learning for COVID-19 Forecasts in the United States</b></br>
        <p>Difan Zou, Lingxiao Wang, Pan Xu, <b>Jinghui Chen</b>, Weitong Zhang and Quanquan Gu, <i>ICLR 2021 Workshop on Machine Learning for Preventingand Combating Pandemics (<strong style="color:red;">MLPCP-ICLR</strong>).</i>
        <a href="https://www.medrxiv.org/content/10.1101/2020.05.24.20111989" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Ensemble Forecasts of Coronavirus Disease 2019 (COVID-19) in the U.S</b></br>
        <p>COVID-19 Forecast Hub Consortium, <b>Jinghui Chen</b>., <i>medRxiv:2020.08.19.20177493, 2020.</i>
        <a href="https://www.medrxiv.org/content/10.1101/2020.08.19.20177493" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>RayS: A Ray Searching Method for Hard-label Adversarial Attack</b></br>
        <p><b>Jinghui Chen</b> and Quanquan Gu, <i>in Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), 
          San Diego, CA, USA 2020. </i>
        <a href="https://arxiv.org/abs/2006.12792" target="_blank">[Paper]</a>
        <a href="https://github.com/uclaml/RayS" target="_blank">[Code]</a>
        </p>
          <!-- <p style="color:blue;">A short version of this paper also appears on ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning and ECCV 2020 Workshop on Adversarial Robustness in the Real World.  </p> -->
      </li>

      <li class="paper">
        <b>Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks</b></br>
        <p><b>Jinghui Chen</b>, Dongruo Zhou, Yiqi Tang, Ziyan Yang, Yuan Cao and Quanquan Gu, <i>in Proceedings of 29th International Joint Conference on Artificial Intelligence (<strong style="color:red;">IJCAI</strong>),
          Yokohama, Japan, 2020. </i>
        <a href="https://arxiv.org/abs/1806.06763" target="_blank">[Paper]</a>
        <a href="https://github.com/uclaml/Padam" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Understanding the Intrinsic Robustness of Image Distributions using Conditional Generative Models</b></br>
        <p>Xiao Zhang<sup><b>E</b></sup>, <b>Jinghui Chen<sup><b>E</b></sup></b>, Quanquan Gu and David Evans, <i>in Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (<strong style="color:red;">AISTATS</strong>),
          Palermo, Sicily, Italy, 2020.  </i>
        <a href="https://arxiv.org/abs/2003.00378" target="_blank">[Paper]</a>
        <a href="https://github.com/xiaozhanguva/Intrinsic-Rob" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks </b></br>
        <p><b>Jinghui Chen</b>, Dongruo Zhou, Jinfeng Yi and Quanquan Gu, <i>in Proceedings of the 34th Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), New York, New York, USA, 2020.  </i>
        <a href="https://arxiv.org/abs/1811.10828" target="_blank">[Paper]</a>
        <a href="https://github.com/uclaml/Frank-Wolfe-AdvML" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization</b></br>
        <p>Pan Xu<sup><b>E</b></sup>, <b>Jinghui Chen<sup><b>E</b></sup></b>, Difan Zou and Quanquan Gu, <i>in Proceedings of the 32nd Advances in Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Montréal, Canada, 2018. 
         <!-- <font color="red"> (Spotlight, 3.5%) </font> -->
         </i>
        <a href="https://arxiv.org/abs/1707.06618" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Covariate Adjusted Precision Matrix Estimation via Nonconvex Optimization</b></br>
        <p><b>Jinghui Chen</b>, Pan Xu, Lingxiao Wang, Jian Ma and Quanquan Gu, <i>in Proceedings of the 35th International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Stockholm, Sweden, 2018. 
          <!-- <font color="red">  (Long Oral Presentation, 4.8%)</font> -->
        </i>
        <a href="http://proceedings.mlr.press/v80/chen18n.html" target="_blank">[Paper]</a>
        <a href="https://github.com/uclaml/nonconvex-CGGM" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Fast Newton Hard Thresholding Pursuit for Sparsity Constrained Nonconvex Optimization</b></br>
        <p><b>Jinghui Chen</b> and Quanquan Gu, <i>in Proceedings of the 23rd ACM SIGKDD Conference
          on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), Halifax, Nova Scotia, Canada, 2017.</i>
        <a href="https://www.kdd.org/kdd2017/papers/view/fast-newton-hard-thresholding-pursuit-for-sparsity-constrained-nonconvex-op" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Robust Wirtinger Flow for Phase Retrieval with Arbitrary Corruption</b></br>
        <p><b>Jinghui Chen</b>, Lingxiao Wang, Xiao Zhang, and Quanquan Gu, <i>arXiv:1704.06256, 2017.</i>
        <a href="https://arxiv.org/abs/1704.06256" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Outlier Detection with Autoencoder Ensembles</b></br>
        <p><b>Jinghui Chen</b>, Saket Sathe, Charu Aggarwal, and Deepak Turaga, <i>in Proceedings of the 17th SIAM International Conference on Data Mining (<strong style="color:red;">SDM</strong>), Houston, Texas, USA, 2017. </i>
        <a href="https://saketsathe.net/downloads/autoencode.pdf" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Stochastic Block Coordinate Gradient Descent for Sparsity Constrained Optimization</b></br>
        <p><b>Jinghui Chen</b> and Quanquan Gu, <i>in Proceedings of the 32th International Conference on Uncertainty in Artificial Intelligence (<strong style="color:red;">UAI</strong>), New York, USA, 2016. </i>
        <a href="http://auai.org/uai2016/proceedings/papers/202.pdf" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>Improved threshold Selection by using Calibrated Probabilities for Random Forest Classifiers</b></br>
        <p>Florian Baumann, <b>Jinghui Chen</b>, Karsten Vogt and Bodo Rosenhahn, <i>in Proceedings of the 12th Conference on Computer and Robot Vision (<strong style="color:red;">CRV</strong>), Halifax, Nova Scotia, Canada,
          2015.  </i>
        <a href="https://ieeexplore.ieee.org/document/7158334" target="_blank">[Paper]</a> 
        </p>
      </li>
    </ol>






        
<!-- paper in psu  --> 


    <ol class="tab-pane" id="at">

       <li class="paper">
        <b>TruthFlow: Truthful LLM Generation via Representation Flow Correction</b> 
        <br>
        <p><u>Hanyu Wang</u>, <u>Bochuan Cao</u>, <u>Yuanpu Cao</u>, and <b>Jinghui Chen</b>, <i>in Proceedings of the 42nd International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vancouver, Canada, 2025. </i>
        <a href="https://arxiv.org/abs/2502.04556" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models</b> 
        <br>
        <p>Yaopei Zeng, <u>Yuanpu Cao</u>, <u>Bochuan Cao</u>, Yurui Chang, <b>Jinghui Chen</b>, and Lu Lin, <i>in Proceedings of the 42nd International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vancouver, Canada, 2025. </i>
        <a href="https://arxiv.org/abs/2410.21471" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection</b></br>
        <p>Lee, Jooyoung, Toshini Agrawal, Adaku Uchendu, Thai Le, <b>Jinghui Chen</b>, and Dongwon Lee, <i>in Proceedings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Albuquerque, New Mexico, 2025. </i>
        <a href="https://arxiv.org/abs/2406.16288" target="_blank">[Paper]</a> </p>    
      </li>


      <li class="paper">
        <b>WordGame: Efficient & Effective LLM Jailbreak via Simultaneous Obfuscation in Query and Response</b> 
        <br>
        <p><u>Tianrong Zhang</u>, <u>Bochuan Cao</u>, <u>Yuanpu Cao</u>, Lu Lin, Prasenjit Mitra and <b>Jinghui Chen</b>, <i> in Findings of the 2025 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL Findings</strong>),  Albuquerque, New Mexico, 2025.</i>
        <a href="https://arxiv.org/abs/2405.14023" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Watch the Watchers! On the Security Risks of Robustness-Enhancing Diffusion Models</b> 
        <br>
        <p>Changjiang Li, Ren Pang, <u>Bochuan Cao</u>, <b>Jinghui Chen</b>, Fenglong Ma, Shouling Ji and Ting Wang, <i>in Proceedings of the 34th USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Seattle, WA, USA, 2025.</i>
        <a href="https://arxiv.org/abs/2406.09669" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization</b> 
        <br>
        <p><u>Yuanpu Cao</u>, <u>Tianrong Zhang</u>, <u>Bochuan Cao</u>, Ziyi Yin, Lu Lin, Fenglong Ma and <b>Jinghui Chen</b>,<i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2406.00045" target="_blank">[Paper]</a>
        </p>
      </li>
 
      <li class="paper">
        <b>DFBA: Data Free Backdoor Attacks</b> 
        <br>
        <p><u>Bochuan Cao</u>, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, <b>Jinghui Chen</b> Bo Li, and Dawn Song, <i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2412.06219" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>FedMeKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection</b> 
        <br>
        <p>Jiaqi Wang<sup><b>E</b></sup>, Xiaochen Wang<sup><b>E</b></sup>, Lingjuan Lyu, <b>Jinghui Chen</b> and Fenglong Ma, <i> in Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Vancouver, Canada, 2024.</i>
        <a href="https://arxiv.org/abs/2408.09227" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models</b> 
        <br>
        <p>Xiaochen Wang<sup><b>E</b></sup>, Jiaqi Wang<sup><b>E</b></sup>, Houping Xiao, <b>Jinghui Chen</b> and Fenglong Ma, <i> in Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (<strong style="color:red;">EMNLP</strong>), Miami, Florida, 2024.</i>
        <a href="https://arxiv.org/abs/2408.10276" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>On the Data Heterogeneity in Adaptive Federated Learning</b></br>
        <p><u>Yujia Wang</u>, <b>Jinghui Chen<sup><b>E</b></sup></b>, <i>in Transactions on Machine Learning Research (<strong style="color:red;">TMLR</strong>), 2024.</i>
        <a href="https://openreview.net/forum?id=hv7iXsiBZE" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM</b> 
        <br>
        <p><u>Bochuan Cao</u><sup><b>E</b></sup>, <u>Yuanpu Cao</u><sup><b>E</b></sup>,  Lu Lin, and <b>Jinghui Chen</b>, <i>in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (<strong style="color:red;">ACL</strong>), Bangkok, Thailand, 2024. </i>
        <a href="https://arxiv.org/abs/2309.14348" target="_blank">[Paper]</a>
        </p>
      </li>


      <li class="paper">
        <b>Jailbreak Open-Sourced Large Language Models via Enforced Decoding</b> 
        <br>
        <p>Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, <u>Bochuan Cao</u>, Lu Lin, Jinyuan Jia, <b>Jinghui Chen</b> and Dinghao Wu, <i>in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (<strong style="color:red;">ACL</strong>), Bangkok, Thailand, 2024. </i>
        <a href="https://arxiv.org/abs/2310.01581" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>FADAS: Towards Federated Adaptive Asynchronous Optimization</b></br>
        <p><u>Yujia Wang</u>, Shiqiang Wang, Songtao Lu and <b>Jinghui Chen</b>, <i>in Proceedings of the 41st International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vienna, Austria, 2024. </i>
        <a href="https://arxiv.org/abs/2407.18365" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>Graph Adversarial Diffusion Convolution</b></br>
        <p>Songtao Liu, <b>Jinghui Chen</b>, Tianfan Fu, Lu Lin, Marinka Zitnik and Dinghao Wu, <i>in Proceedings of the 41st International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Vienna, Austria, 2024. </i>
        <a href="https://arxiv.org/abs/2406.02059" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections</b> 
        <br>
        <p><u>Yuanpu Cao</u>, <u>Bochuan Cao</u> and <b>Jinghui Chen</b>, <i> in Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Mexico City, Mexico, 2024.</i>
        <a href="https://arxiv.org/abs/2312.00027" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning</b> 
        <br>
        <p><u>Tianrong Zhang</u>, Zhaohan Xi, Ting Wang, Prasenjit Mitra and <b>Jinghui Chen</b>, <i> in Proceedings of the 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong style="color:red;">NAACL</strong>), Mexico City, Mexico, 2024.</i>
        <a href="https://arxiv.org/abs/2406.04478" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration</b></br>
        <p><u>Yujia Wang</u>, <u>Yuanpu Cao</u>, <u>Jingcheng Wu</u>, <u>Ruoyu Chen</u> and <b>Jinghui Chen</b>, <i>in Proceedings of the 25th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Vienna, Austria, 2024.</i> 
        <a href="https://openreview.net/forum?id=4aywmeb97I" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>Backdoor Contrastive Learning via Bi-level Trigger Optimization</b></br>
        <p><u>Weiyu Sun</u>, Xinyu Zhang, Hao Lu, Ying-Cong Chen, Ting Wang, <b>Jinghui Chen</b> and Lu Lin, <i>in Proceedings of the 25th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Vienna, Austria, 2024.</i> 
        <a href="https://openreview.net/forum?id=oxjeePpgSP" target="_blank">[Paper]</a> </p>
      </li>

      <li class="paper">
        <b>VQAttack: Transferable Adversarial Attacks on Visual Question Answering via Pre-trained Models</b> 
        <br>
        <p>Ziyi Yin, Muchao Ye, <u>Tianrong Zhang</u>, Jiaqi Wang, Han Liu, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Vancouver, Canada, 2024. </i>
        <a href="https://arxiv.org/abs/2402.11083" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>On the Difficulty of Defending Contrastive Learning against Backdoor Attacks</b> 
        <br>
        <p>Changjiang Li, Ren Pang, <u>Bochuan Cao</u>, Zhaohan Xi, <b>Jinghui Chen</b>, Shouling Ji and Ting Wang, <i>in Proceedings of the 33rd USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Philadelphia, PA, USA, 2024.</i>
        <a href="https://arxiv.org/abs/2312.09057" target="_blank">[Paper]</a>
        </p>
       </li>


      <li class="paper">
        <b>Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?</b> 
        <br>
        <p>Yuanxin Zhuang, Chuan Shi, Mengmei Zhang, <b>Jinghui Chen</b>, Lingjuan Lyu, Pan Zhou and Lichao Sun,  <i>in Proceedings of the 33rd USENIX Security Symposium (<strong style="color:red;">USENIX</strong>), Philadelphia, PA, USA, 2024.</i>
        <a href="https://www.usenix.org/conference/usenixsecurity24/presentation/zhuang" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>Federated Learning with Projected Trajectory Regularization</b> 
        <br>
        <p><u>Tiejin Chen</u><sup><b>E</b></sup>, <u>Yuanpu Cao</u><sup><b>E</b></sup>, <u>Yujia Wang</u><sup><b>E</b></sup>, Cho-Jui Hsieh, and <b>Jinghui Chen</b>, <i>arXiv:2312.14380, 2023. </i>
        <a href="https://arxiv.org/abs/2312.14380" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI</b> 
        <br>
        <p><u>Bochuan Cao</u>, Changjiang Li, Ting Wang, Jinyuan Jia, Bo Li and <b>Jinghui Chen</b>, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2310.19248" target="_blank">[Paper]</a>
        </p>
       </li>

      <li class="paper">
        <b>VLATTACK: Multimodal Adversarial Attacks on Vision-Language Tasks via Pre-trained Models</b><br>
        <p>Ziyi Yin, Muchao Ye, <u>Tianrong Zhang</u>, Tianyu Du, Jinguo Zhu, Han Liu, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2310.04655" target="_blank">[Paper]</a> 
        </p>
      </li>
 
      <li class="paper">
        <b>A3FL: Adversarially Adaptive Backdoor Attacks to Federated Learning</b></br>
        <p>Hangfan Zhang, Jinyuan Jia, <b>Jinghui Chen</b>, Lu Lin and Dinghao Wu, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://openreview.net/forum?id=S6ajVZy6FA" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks</b></br>
        <p>Tianyu Du, Zhaohan Xi, Changjiang Li, Ren Pang, Shouling Ji, <b>Jinghui Chen</b>, Fenglong Ma and Ting Wang, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2309.13256" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>UniT: A Unified Look at Certified Robust Training against Text Adversarial Perturbation</b></br>
        <p>Muchao Ye, Ziyi Yin, <u>Tianrong Zhang</u>, Tianyu Du, <b>Jinghui Chen</b>, Ting Wang and Fenglong Ma, <i>in Proceedings of the 37th Conference on Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, Louisiana, USA, 2023. </i>
        <a href="https://openreview.net/forum?id=oGxE2Nvlda" target="_blank">[Paper]</a> 
        </p>
      </li>

      <li class="paper">
        <b>RoCourseNet: Robust Training of a Prediction Aware Recourse Model</b></br>
        <p>Hangzhi Guo, Feiran Jia, <b>Jinghui Chen</b>, Anna Squicciarini and Amulya Yadav, <i>in Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (<strong style="color:red;">CIKM</strong>), Birmingham, UK, 2023. </i>
        <a href="https://arxiv.org/abs/2206.00700" target="_blank">[Paper]</a> 
        </p>
    <!--     <p style="color:blue;">A short version of this paper also appears on ICML 2022 Workshop on Adversarial Machine Learning Frontiers. </p>
           <li class="paper-buttons">
              <a class="button" href="https://arxiv.org/abs/2206.00700" target="_blank">Paper</a>
          </li> -->
      </li>


      <li class="paper">
        <b>PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text</b></br>
        <p>Muchao Ye, <b>Jinghui Chen</b>, Chenglin Miao, Han Liu, Ting Wang and Fenglong Ma, <i> in Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), San Diego, CA, USA, 2023.</i>
        <a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599461" target="_blank">[Paper]</a>
        </p>           
      </li>

      <li class="paper">
        <b>Benign Overfitting in Adversarially Robust Linear Classification</b></br>
        <p><b>Jinghui Chen<sup><b>E</b></sup></b>, Yuan Cao<sup><b>E</b></sup>, and Quanquan Gu, <i> in Proceedings of the 39th Conference on Uncertainty in Artificial Intelligence (<strong style="color:red;">UAI</strong>), Pittsburgh, PA, USA, 2023.</i> <a href="https://arxiv.org/abs/2112.15250" target="_blank">[Paper]</a> </p>
         <!-- <p style="color:blue;">A short version of this paper also appears on ICML 2021 Workshop on Overparameterization: Pitfalls and Opportunities.</p> -->
      </li>

      <li class="paper">
        <b>Graph Contrastive Backdoor Attacks</b></br>
        <p>Hangfan Zhang, <b>Jinghui Chen</b>, Lu Lin, Jinyuan Jia and Dinghao Wu, <i> in Proceedings of the 40th International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Hawaii, USA, 2023. </i> 
        <a href="https://proceedings.mlr.press/v202/zhang23e/zhang23e.pdf" target="_blank">[Paper]</a> </p>
      </li>


      <li class="paper">
        <b>Do Language Models Plagiarize?</b></br>
        <p>Lee, Jooyoung, Thai Le, <b>Jinghui Chen</b>, and Dongwon Lee, <i>in Proceedings of the ACM Web Conference (<strong style="color:red;">WWW</strong>), Austin, Texas, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2203.07618" target="_blank">[Paper]</a> </p>    
      </li>


      <li class="paper">
        <b>Spectral Augmentation for Self-Supervised Learning on Graphs</b></br>
        <p>Lu Lin, <b>Jinghui Chen</b>, Hongning Wang, <i> in Proceedings of the 11th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Kigali Rwanda, 2023. </i>
        <a href="https://arxiv.org/abs/2210.00643" target="_blank">[Paper]</a>
        <a href="https://github.com/Louise-LuLin/GCL-SPAN" target="_blank">[Code]</a>
        </p>
        <!-- <p style="color:blue;">A short version of this paper also appears on NeurIPS 2022 Workshop on New Frontiers in Graph Learning. </p> -->         
      </li>

<!--       <li class="paper">
        <b>Robustness for Free: Adversarially Robust Anomaly Detection Through Diffusion Model</b></br>
        <p><u>Yuanpu Cao</u>, Lu Lin, and <b>Jinghui Chen</b>, <i> Technical Report. </i>
        <a href="https://openreview.net/forum?id=imIlOpuEsi" target="_blank">[Paper]</a>
        </p>
      </li> -->


      <li class="paper">
        <b>On the Vulnerability of Backdoor Defenses for Federated Learning</b></br> 
        <p><u>Pei Fang</u> and <b>Jinghui Chen</b>, 
        <i>  in Proceedings of the 37th Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Washington DC, USA, 2023. </i>
        <a href="https://arxiv.org/abs/2301.08170" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/Focused-Flip-Federated-Backdoor-Attack" target="_blank">[Code]</a>
        </p>
          <!-- <p style="color:blue;">A short version of this paper also appears on International Workshop on Federated Learning: Recent Advances and New Challenges in Conjunction with NeurIPS 2022. </p> -->
        </li>
 
      <li class="paper">
        <b>One-shot Neural Backdoor Erasing via Adversarial Weight Masking</b></br>
        <p><u>Shuwen Chai</u>  and <b>Jinghui Chen</b>, <i> in Proceedings of the 36th Advances in Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), New Orleans, LA, USA, 2022. </i>
        <a href="https://arxiv.org/abs/2207.04497" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/AWM" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Accelerating Adaptive Federated Optimization with Local Gossip Communications</b></br>
        <p><u>Yujia Wang</u>, <u>Pei Fang</u> and <b>Jinghui Chen</b>, <i> in International Workshop on Federated Learning: Recent Advances and New Challenges in Conjunction with NeurIPS 2022 (<strong style="color:red;">FL-NeurIPS</strong>), 2022. </i>
        <a href="https://openreview.net/forum?id=wwXb1qmcBuD" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>How Powerful is Implicit Denoising in Graph Neural Networks</b></br>
        <p>Songtao Liu, Zhitao Ying, Hanze Dong, Lu Lin, <b>Jinghui Chen</b> and Dinghao Wu, <i>NeurIPS 2022 Workshop on New Frontiers in Graph Learning (<strong style="color:red;">GLFrontiers-NeurIPS</strong>). </i>
        <a href="https://arxiv.org/abs/2209.14514" target="_blank">[Paper]</a>
        </p>
      </li>
 

      <li class="paper">
        <b>LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization</b></br>
        <p>Muchao Ye, <b>Jinghui Chen</b>, Chenglin Miao, Ting Wang and Fenglong Ma, <i> in Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong style="color:red;">KDD</strong>), Washington DC, USA, 2022. </i>
        <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539357" target="_blank">[Paper]</a>
        </p>
      </li>

      <li class="paper">
        <b>Communication-Efficient Adaptive Federated Learning</b></br>
        <p><u>Yujia Wang</u>, Lu Lin and <b>Jinghui Chen</b>, <i> in Proceedings of the 39th International Conference on Machine Learning (<strong style="color:red;">ICML</strong>), Baltimore, Maryland, USA, 2022. </i>
        <a href="https://arxiv.org/abs/2205.02719" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/FedCAMS" target="_blank">[Code]</a>
        </p> 
      </li> 
 

      <li class="paper">
        <b>Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations</b></br>
        <p><u>Weiqi Peng</u> and <b>Jinghui Chen</b>, <i>in Proceedings of the 10th International Conference on Learning Representations (<strong style="color:red;">ICLR</strong>), Virtual, 2022.</i>
        <a href="https://openreview.net/forum?id=6VpeS27viTq" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/Learnability-Lock" target="_blank">[Code]</a>
        </p>
      </li>

      <li class="paper">
        <b>Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization</b></br>
        <p><u>Yujia Wang</u>, Lu Lin and <b>Jinghui Chen</b>, <i>in Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (<strong style="color:red;">AISTATS</strong>), Virtual, 2022. </i>
        <a href="https://arxiv.org/abs/2111.00705" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/CD-Adam" target="_blank">[Code]</a>
        </p>
        <!-- <p style="color:blue;">A short version of this paper also appears on International Workshop on Trustable, Verifiable and Auditable Federated Learning in Conjunction with AAAI 2022 (FL-AAAI-22). </p> -->
      </li>

      <li class="paper">
        <b>Efficient Robust Training via Backward Smoothing</b></br>
        <p><b>Jinghui Chen</b>, Yu Cheng, Zhe Gan, Quanquan Gu and Jingjing Liu, <i>In Proceedings of the 36th AAAI Conference on Artificial Intelligence (<strong style="color:red;">AAAI</strong>), Vancouver, BC, Canada, 2022.</i>
        <a href="https://arxiv.org/abs/2010.01278" target="_blank">[Paper]</a>
        <a href="https://github.com/jinghuichen/BackwardSmoothing" target="_blank">[Code]</a>
        </p>
      </li>
   
      <li class="paper">
        <b>Do Wider Neural Networks Really Help Adversarial Robustness?</b></br>
        <p>Boxi Wu<sup><b>E</b></sup>, <b>Jinghui Chen<sup><b>E</b></sup></b>, Deng Cai, Xiaofei He and Quanquan Gu, <i>in Proceedings of the 35th Advances in Neural Information Processing Systems (<strong style="color:red;">NeurIPS</strong>), Virtual, 2021.</i>
        <a href="https://arxiv.org/abs/2010.01279" target="_blank">[Paper]</a>
        </p>
      </li>
       
      
    </ol>

  </div>
</div>


<!-- ========== Research ========== -->
<div class="docs-section" id="research">
  <h4>Research</h4>

  <p>
The research of our lab is focused on different aspects of machine learning (efficiency, robustness, interpretability, responsibility, trustworthiness) and their applications in computer vision, graph learning, anomaly detection, cybersecurity, recommendation systems, computational genomics, etc. Some of our current research projects are:
  </p>
  <div class="row">
        
 
        <!-- <article class="major">
          <Li> Adversarial Machine Learning </Li>
          <Li> Nonconvex Optimization in Machine Learning </Li>
            <Li> Evasion/Poisoning Attacks and Defenses on Machine Learning Systems </Li>
            <Li> Federated and Distributed Machine Learning </Li>
            <Li> Explainable/Interpretable Machine Learning </Li>
            <Li> Security and Privacy Issues in Machine Learning </Li>
        </article>-->


      <div class="six columns">
        
        <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/llm.png" class="u-full-width-height"  height="115" />
            </div>
            <div class="project-caption">
              <b>Trustworthiness and Saftey Issues in Large Language Models </b> <br/>
              Studying the vulnerabilities inside the current LLMs and how we can improve them for better trustworthiness.
            </div>
        </div>

        

        
        <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/opt.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Optimization in Machine Learning</b> <br/>
              Studying the convergence of machine learning optimizers including adaptive gradient optimizers and designing new generation of optimizers for deep learning.
            </div>
        </div>

        <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/backdoor.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Poisoning/Backdoor Attacks and Defenses  </b> <br/>
              Studying the effects of poisoning and backdoor attacks on deep learning models, as well as how to mitigate those threats.
            </div>
        </div>

        
        
      </div>
        
      <div class="six columns">
        <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/fedml.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Federated Machine Learning</b> <br/>
              Addressing the emerging challenges for Federated Learning in practical scenarios such as data and model heterogeneity, communication efficiency, as well as security and privacy issues.
            </div>
        </div>

        <div class="project-container">
           <div class="project-image-container">    
                <img src="assets/research-pics/advml.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Adversarial Robustness in Machine Learning</b> <br/>
              Evaluating, understanding, and improving adversarial robustness in deep learning as well as studying the theoretical foundations behind adversarial training and robust learning.
            </div>
        </div>

        
        <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/gnn.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Robustness in Graph Nerual Networks</b> <br/>
              Improving the robustness of the current graph neural networks again graph structural/feature perturbations.
            </div>
        </div>

        <!-- <div class="project-container">
            <div class="project-image-container">    
                <img src="assets/research-pics/learnability.png" class="u-full-width-height" />
            </div>
            <div class="project-caption">
              <b>Learnability Attacks on Machine Learning Systems </b> <br/>
              Studying how to manipulate data to make machine learning model unlearnable.
            </div>
        </div> -->

        
      </div>

      

        
  </div>

</div>

 
 

<!-- ========== Students ========== -->
<div class="docs-section" id="students">
  <h4>Students</h4>

  <!-- <ul class="tab-nav">
    <li><div class="button active" data-ref="#phd">Ph.D.</div></li>
    <li><div class="button" data-ref="#master">Master</div></li>
    <li><div class="button" data-ref="#undergrad">Undergrad</div></li>    
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="phd">
      
      
        <div class="student">
          
          <p class="title"><b><a href=''>Yujia Wang</a></b> (Spring 2022 -  )</p> 
          
        </div>   
      
    </div>

    <div class="tab-pane" id="master">
      
      
    </div>

    <div class="tab-pane" id="undergrad">
      
      
    </div>    

  </div> -->

  <div class="student">  

  <b>Current Ph.D. Students</b> 
  <ul>    
      <li><b> <a>Yujia Wang</a></b> (Ph.D., Spring 2022 - Present) </b>
      <li><b> <a>Bochuan Cao</a></b> (Ph.D., Fall 2022 - Present) </b>
      <li><b> <a>Yuanpu Cao</a></b> (Ph.D., Fall 2023 -  Present) </b> 
      <li><b> <a>Hanyu Wang</a></b> (Ph.D., Fall 2024 -  Present) </b> 
  </ul>

  <b>Current Undergrad/Master/Intern Students</b> 
  <ul>    
      <li><b> <a>Ben Hsiao</a></b> (Undergrad at PSU, Fall 2023 -  Present) </b>
      <li><b> <a>Malcolm Zerbe</a></b> (Undergrad at PSU, Fall 2023 -  Present) </b>
      <li><b> <a>Bharavi Misra</a></b> (Undergrad at PSU, Fall 2023 -  Present) </b>
      <li><b> <a>Vijay Nagarajan</a></b> (Student at North Allegheny High School, Summer 2024 -  Present) </b>
      <li><b> <a>Siddharth Shankar</a></b> (Student at South Brunswick High School, Summer 2024 -  Present) </b>
  </ul>

   <b>Alumni</b> 
   <ul>   
      <li><b> <a>Avi Bewtra</a></b> (Undergrad at PSU, Fall 2021 -  Spring 2022, Now at Amazon) </b>
      <li><b> <a>Weiqi Peng</a></b> (Research Intern, Fall 2021 - Spring 2022, Now at Amazon) </b>
      <li><b> <a>Shuwen Chai</a></b> (Research Intern, Fall 2021 -  Spring 2022, Now a Ph.D. student at Northwestern University) </b>
      <li><b> <a>Pei Fang</a></b> (Research Intern, Fall 2021 -  Fall 2023, Now at Ant Financial) </b>
      <li><b> <a>Weiyu Sun</a></b> (Research Intern, Summer 2022 -  Fall 2023, Now a Ph.D. student at Georgia Tech) </b>
      <li><b> <a>Tiejin Chen</a></b> (Research Intern, Summer 2022 -  Spring 2023, Now a Ph.D. student at ASU) </b>
      <li><b> <a>Aryan Harshanan Patil</a></b> (Undergrad at PSU, Fall 2022 -  Spring 2023, Now at JPMorgan Chase) </b>
      <li><b> <a>Sirui Qi</a></b> (Undergrad at PSU, Fall 2022 -  Spring 2023) </b>
      <li><b> <a>Sooraj Narayanan Sekar</a></b> (Undergrad at PSU, Fall 2022 -  Spring 2023, Now a master at Georgia Tech)  </b>
      <li><b> <a>Jingcheng Wu</a></b> (Research Intern, Spring 2023 -  Fall 2023, Now at Google) </b>
      <li><b> <a>Ruoyu Chen</a></b> (Research Intern, Spring 2023 -  Fall 2023, Now at Observe, Inc.) </b>
      <li><b> <a>Tianrong Zhang</a></b> (former Ph.D. Fall 2022 - Fall 2024) </b>
  </ul>
  </div>   

</div>


<!-- ========== TEACHING ========== -->
<span class="anchor" id="teaching"></span>
<div class="docs-section">
  <h4>Teaching</h4>

 

  <p>
  <ul>
  <li><b> Spring 2025: <a href=https://jinghuichen.github.io/DS440-25Spring/>DS440: Data Sciences Capstone Course</a>  </b>
  <li><b> Fall 2024: <a href=https://jinghuichen.github.io/SRA221-24Fall/>SRA221: Overview of Information Security</a>  </b>
  <li><b> Spring 2024: <a href=https://jinghuichen.github.io/SRA221-24Spring/>SRA221: Overview of Information Security</a>  </b>
  <li><b> Fall 2023: <a href=https://jinghuichen.github.io/DS310-23Fall/>DS310: Machine Learning for Data Analytics</a>  </b>
  <li><b> Spring 2023: <a href=https://jinghuichen.github.io/SRA221-23Spring/>SRA221: Overview of Information Security</a>  </b>
  <li><b> Fall 2022: <a href=https://jinghuichen.github.io/AdvML22Fall/>IST597: Special Topics on Adversarial Machine Learning</a>  </b>
  <li><b> Spring 2022: <a href=https://jinghuichen.github.io/SRA221-22Spring/>SRA221: Overview of Information Security</a>  </b>
  <li><b> Fall 2021: <a href=https://jinghuichen.github.io/AdvML21Fall/>IST597: Special Topics on Adversarial Machine Learning</a>  </b>

  </ul>

  </p>

</div>


<!-- ========== Service ========== -->
<span class="anchor" id="service"></span>
<div class="docs-section">
  <h4>Acadamic Service</h4>

      
    <b>Aera Chair/Senior Program Committee</b> 

    <ul>
      <Li> Neural Information Processing Systems (NeurIPS)</Li>
      <Li> International Joint Conference on Artificial Intelligence (IJCAI)</Li>
      <Li> AAAI Conference on Artificial Intelligence (AAAI)</Li> 
    </ul>

    <b>Program Committee/Reviewer</b> 
    <ul>

      <Li> International Conference on Machine Learning (ICML)</Li>
      <Li> International Conference on Learning Representations (ICLR)</Li>
      <Li> The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) </Li>
      <Li> International Conference on Computer Vision (ICCV)</Li>
      <Li> ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</Li>
      <Li> International Conference on Artificial Intelligence and Statistics (AISTATS)</Li>
      <Li> The Conference on Uncertainty in Artificial Intelligence (UAI)</Li>
      <Li> IEEE International Conference on Big Data (BigData)</Li> 
      <Li> SIAM International Conference on Data Mining (SDM) </Li> 
    </ul>

    <b>Journal Reviewer</b> 
    <ul>
      <Li> Journal of Machine Learning Research (JMLR)</Li>
      <Li> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</Li>
      <Li> IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</Li>
      <Li> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</Li>
      <Li> IEEE Transactions on Knowledge and Data Engineering (TKDE)</Li>
      <Li> IEEE Signal Processing Letters (SPL)</Li>
      <Li> ACM Transactions on Knowledge Discovery from Data (TKDD)</Li>
      <Li> Journal of Artificial Intelligence Research (JAIR)</Li>
      <Li> Journal of Industrial and Management Optimization (JIMO) </Li>
      <Li> Journal of Computational and Applied Mathematics (ELSCAM)</Li>
      <Li> Neural Networks (NEUNET)</Li>
      <Li> BioData Mining (BIDM)</Li>
      <Li> Machine Learning (MACH)</Li>
      <Li> Mathematical Biosciences and Engineering (MBE)</Li>
      <Li> Reviews in Biomedical Engineering (RBME)</Li>
      <Li> Pattern Recognition Letters (PRLETTERS)</Li>
      <Li> Transactions on Big Data (TBD)</Li>
      <Li> Machine Learning and Knowledge Extraction (MAKE)</Li>
      <Li> Advanced Theory and Simulations </Li>
      <Li> Frontiers in Artificial Intelligence</Li>
      <Li> PLOS ONE</Li>
      <Li> PLOS Global Public Health</Li>
      <Li> Applied Science</Li>
      <Li> Algorithms</Li>
      <Li> Electronics</Li>
      <Li> Neurocomputing</Li>
      <Li> Entropy</Li>
    </ul>
 

</div>
 
 


<div class="footer">
  <div class="row">
     <font size="2">© Copyright 2022 Jinghui Chen. Powered by <a href="https://jekyllrb.com">jekyll</a> with theme from <a href="http://web.media.mit.edu/~msaveski/">Martin Saveski</a>. Hosted by GitHub Pages. </font>
  </div>
</div>

 

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
